# PRODIGY_GA_TASKS
TASK 1-GPT-2: The Fine-Tuning of the OpenAI Model to Make Text This is a tuned version on its specific data set, generating contextual text and coherent sentences through the use of the GPT-2 model-an OpenAI model.
TASK 2-This project creates images based on a text prompt using pre-trained generative models - DALL-E-mini or Stable Diffusion for instance. In that regard, this then shows how language can be translated into visual content.
TASK 3-This project presents text generation using Markov chains. It predicts the next word or character in the sequence, given prior input, making use of an algorithm based on Markov chains. The design of such an algorithm builds on a statistical model of the process of text generation, and it involves transitions with a primary focus on probabilistic words or characters.
TASK 4-This pix2pix uses a conditional Generative Adversarial Network for translating images between two different domains-say, automatically converting a sketch to an image. The model learns how to map these pairs through training on pairs of images.
TASK 5-It takes an image and transfers the artistic style to another content; the idea is to transfer the content of one image to another image, where its style is applied. Extracted content and style features are used via a neural network; the style is then transferred into the target image while preservations were sustained for the content.
 These were implemented in Google Colab.
